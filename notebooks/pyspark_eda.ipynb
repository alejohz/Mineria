{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "import human.plotly_template\n",
    "\n",
    "pio.templates.default = \"plotly+human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://merged-tweets/testing-sample/test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ps.from_pandas(df).to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.replace(float('nan'), None)\n",
    " .agg(*[F.expr(f'count({col}) as {col}') for col in df.columns])\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy('id')\n",
    "df.select('*', F.count('id').over(w).alias('dupeCount'))\\\n",
    "    .where('dupeCount > 1')\\\n",
    "    .drop('dupeCount')\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('lang').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('favorited').count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('retweeted').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('possibly_sensitive').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Descriptive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Daily Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_plot = (df.select(F.date_format('created_at','yyyy-MM-dd').alias('created_at'))\n",
    " .groupby('created_at')\n",
    " .count()\n",
    " .withColumnRenamed('count', 'size'))\n",
    "px.line(df_plot.toPandas().sort_values(by=\"created_at\"), x='created_at', y='size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Monthly Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = (df.select(F.date_format('created_at', 'yyyy-MM').alias('created_at'))\n",
    " .groupby('created_at')\n",
    " .count()\n",
    " .withColumnRenamed('count', 'size'))\n",
    "px.line(df_plot.toPandas().sort_values(by=\"created_at\"), x='created_at', y='size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Retweets and favs distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Including 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limits, count = df.select('retweet_count').rdd.flatMap(lambda x: x).histogram(list(range(0, 100, 10)))\n",
    "limits = np.array(limits)\n",
    "fig = px.histogram(x=(limits[:-1] + limits[1:]) / 2 + 2, y=count, nbins=10, range_x=[0, 100])\n",
    "fig.update_xaxes(title='retweet_count').update_yaxes(title='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limits, count = df.select('favorite_count').rdd.flatMap(lambda x: x).histogram(list(range(0, 100, 10)))\n",
    "limits = np.array(limits)\n",
    "fig = px.histogram(x=(limits[:-1] + limits[1:]) / 2 + 2, y=count, nbins=10, range_x=[0, 100])\n",
    "fig.update_xaxes(title='favorite_count').update_yaxes(title='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Excluding 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limits, count = df.filter(df.retweet_count > 0).select(\"retweet_count\").rdd.flatMap(lambda x: x).histogram(list(range(0, 100, 10)))\n",
    "limits = np.array(limits)\n",
    "fig = px.histogram(x=(limits[:-1] + limits[1:]) / 2 + 2, y=count, nbins=10, range_x=[0, 100])\n",
    "fig.update_xaxes(title='retweet_count').update_yaxes(title='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limits, count = df.filter(df.favorite_count > 0).select(\"favorite_count\").rdd.flatMap(lambda x: x).histogram(list(range(0, 100, 10)))\n",
    "limits = np.array(limits)\n",
    "fig = px.histogram(x=(limits[:-1] + limits[1:]) / 2 + 2, y=count, nbins=10, range_x=[0, 100])\n",
    "fig.update_xaxes(title='favorite_count').update_yaxes(title='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_array = np.array(df.select(\"full_text\").collect()).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(text_array, n_process=4) # This will require a better handling -> https://spacy.io/usage/processing-pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This preprocessing can be done in the dataframe (enabling the comparison between dask and pyspark)\n",
    "def is_token_allowed(token, pos_tag=None):\n",
    "    matches_pos = True if pos_tag is None else token.pos_ == pos_tag\n",
    "    if (not token or not token.text.strip() or\n",
    "            token.is_stop or token.is_punct or not matches_pos):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def preprocess_token(token, lemma=False):\n",
    "    if lemma:\n",
    "        return token.lemma_.strip().lower()\n",
    "    return token.text.strip().lower()\n",
    "\n",
    "\n",
    "def get_word_lists(docs, lemma=False):\n",
    "    words = []\n",
    "    nouns = []\n",
    "    verbs = []\n",
    "    for doc in docs:\n",
    "        for token in doc:\n",
    "            if is_token_allowed(token):\n",
    "                words.append(preprocess_token(token, lemma=lemma))\n",
    "\n",
    "                if is_token_allowed(token, pos_tag='NOUN'):\n",
    "                    nouns.append(preprocess_token(token, lemma=lemma))\n",
    "\n",
    "                if is_token_allowed(token, pos_tag='VERB'):\n",
    "                    verbs.append(preprocess_token(token, lemma=lemma))\n",
    "\n",
    "    return words, nouns, verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## No lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "words, nouns, verbs = get_word_lists(docs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(50)\n",
    "\n",
    "noun_freq = Counter(nouns)\n",
    "common_nouns = noun_freq.most_common(50)\n",
    "\n",
    "verb_freq = Counter(verbs)\n",
    "common_verbs = verb_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(common_words, columns=['word', 'count'])\n",
    "px.bar(df_plot.sort_values('count'), x='count', y='word', text_auto=True, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Noun count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(common_nouns, columns=['word', 'count'])\n",
    "px.bar(df_plot.sort_values('count'), x='count', y='word', text_auto=True, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Verb count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(common_verbs, columns=['word', 'count'])\n",
    "px.bar(df_plot.sort_values('count'), x='count', y='word', text_auto=True, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs = nlp.pipe(text_array, n_process=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "words, nouns, verbs = get_word_lists(docs, lemma=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(50)\n",
    "\n",
    "noun_freq = Counter(nouns)\n",
    "common_nouns = noun_freq.most_common(50)\n",
    "\n",
    "verb_freq = Counter(verbs)\n",
    "common_verbs = verb_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(common_words, columns=['word', 'count'])\n",
    "px.bar(df_plot.sort_values('count'), x='count', y='word', text_auto=True, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Noun count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(common_nouns, columns=['word', 'count'])\n",
    "px.bar(df_plot.sort_values('count'), x='count', y='word', text_auto=True, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Verb count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(common_verbs, columns=['word', 'count'])\n",
    "px.bar(df_plot.sort_values('count'), x='count', y='word', text_auto=True, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mineria-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "eeede23745af28c7451b9be4ffc9b6af6bb87090e18ce2d9f28f4e00d378b601"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
